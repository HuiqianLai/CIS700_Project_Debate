[Round 1: Pro Opening Statement] Baidu (Pro First Speaker): Data journalism's rise should be prioritized, even if qualitative reporting declines. The Panama Papers investigation, powered by data analysis, exposed global corruption networks that traditional reporting alone couldn't. "Sacrificing depth for breadth" ignores how data uncovers systemic patterns invisible in single stories. Risks of losing narrative nuance are outweighed by data's ability to democratize access to truths hidden in volumes of records. Can we afford to ignore tools that reveal what individual stories cannot?
[Round 1: Con Opening Statement] Claude (Con First Speaker): The proposition's false dichotomy ignores that data journalism depends fundamentally on qualitative reporting to provide context, verification, and human meaning. The Panama Papers example actually proves our point: investigative journalists spent months conducting interviews, building source relationships, and crafting narratives to make the data intelligible and actionable for the public. The claim that we must accept "sacrificing depth for breadth" misunderstands how journalism creates impact—raw data without skilled interpretation becomes meaningless noise that serves neither truth nor accountability. Prioritizing data at qualitative journalism's expense risks producing technically sophisticated but socially hollow reporting that fails to connect with audiences or drive change. If data alone could reveal truth, why did the Panama Papers require 400 journalists across 80 countries doing traditional investigative work?
[Round 2: Pro Rebuttal/Supplement] DeepSeek (Pro Second Speaker): The opposition claims data requires "traditional investigative work." This misunderstands data's unique power. The Panama Papers' scale was only possible because a massive dataset was the primary evidence. Their "skilled interpretation" is precisely data journalism. Sacrificing some qualitative depth is necessary to expose systemic truths hidden in numbers that anecdotes cannot reveal. Would any qualitative investigation alone have uncovered the global network revealed by the data?
[Round 2: Con Rebuttal/Supplement] GPT-5 (Con Second Speaker): We oppose sacrificing qualitative reporting; the strongest investigations blend methods.
Cambridge Analytica came to light through whistleblowers, interviews, and documents; even the Panama Papers demanded months of door-knocking, legal context, and right-of-reply to separate illegality from mere secrecy.
You say, "Sacrificing some qualitative depth is necessary"; that shortcut risks falsely implicating people, missing local law nuances, and mistaking correlation for causation.
When what gets measured governs coverage, biased datasets and opaque algorithms steer narratives, silencing communities who aren't counted; preserving qualitative capacity checks those biases and grounds numbers in lived reality.
No one claims "alone"; we reject false choices between scale and understanding.

Data is a powerful lens, but not a compass.
If we privilege it over qualitative work, the worst-case is technocratic journalism that amplifies institutional biases and overlooks harm.
Our approach keeps both, letting data reveal patterns and qualitative reporting test, humanize, and correct them.
Who will speak for what the spreadsheet never recorded?
[Round 3: Pro Cross-examination] Baidu (Pro First Speaker): Claim: Prioritizing data journalism doesn’t erase qualitative rigor but redirects resources to scale impact where it matters most.  

Example: The COVID-19 pandemic’s early spread was tracked via data models, which directed qualitative teams to hotspots for deeper reporting—saving lives through speed, not sacrifice.  

“Data is a powerful lens, but not a compass.” Yet compasses fail without maps; data provides the map, while qualitative work calibrates direction.  

Risks exist, but neglecting data risks slower responses to crises. Scaling data doesn’t eliminate qualitative teams—it lets them focus on nuance where algorithms can’t tread.  

If datasets risk bias, isn’t refusing to scale data journalism a bigger bias—one that silences entire communities by leaving their stories unmapped?
[Round 3: Con Cross-examination] Claude (Con First Speaker): Your COVID example proves our point—data models predicted hotspots, but qualitative journalists uncovered nursing home neglect, PPE shortages, and policy failures that numbers alone never revealed. You claim data provides the map while qualitative work calibrates direction, yet maps without context lead nowhere—remember when early COVID data missed asymptomatic spread because models lacked on-the-ground human insight. Scaling data at qualitative journalism's expense doesn't focus resources; it creates blind spots where algorithms miss what only human investigation reveals—corruption, systemic discrimination, and institutional failures invisible in datasets. Your framing presents a false choice: we can maintain both without sacrificing one, but your proposition explicitly accepts qualitative journalism as collateral damage, which is precisely the bias that silences communities whose stories exist beyond spreadsheets. If data truly complements rather than replaces qualitative work, why does your motion require sacrifice as the acceptable cost?
[Round 4: Pro Closing Statement] DeepSeek (Pro Second Speaker): Our position champions the necessary evolution of journalism to serve the public good effectively. Data journalism provides the scalable, objective framework needed to hold power accountable in a complex world. They claim we "silence communities beyond spreadsheets," but data precisely amplifies marginalized voices by revealing systemic patterns anecdotes miss. The worst outcome is a news industry unable to provide verifiable facts at the speed and scale modern crises demand. Prioritizing data-driven reporting is the only way to ensure journalism remains a relevant and powerful force for truth.
[Round 4: Con Closing Statement] GPT-5 (Con Second Speaker): Sacrificing qualitative reporting for data-first journalism weakens truth-seeking.
Before Grenfell, residents’ warnings documented cladding dangers while official compliance data reassured; privileging the dataset over voices proved fatal.
They say "data precisely amplifies marginalized voices"; when datasets are missing or misclassified, those voices vanish.
Data is essential, but a newsroom that sidelines interviews, observation, and trust-building misses causes, misreads context, and becomes easy prey for algorithmic bias and performative dashboards.
Worst case of our model is slower scale; worst case of theirs is systemic blind spots that legitimize harm—preserving qualitative capacity alongside data minimizes that risk.

We agree data matters for speed, scope, and verification.
But truth also lives in contradictions, outliers, and testimony that no spreadsheet captures.
Keep data journalism prominent without cannibalizing qualitative beats, or you amputate the very sensors that warn before the numbers move.
If the dataset is wrong, who will notice when the reporters are gone?